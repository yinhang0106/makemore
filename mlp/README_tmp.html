<!DOCTYPE html>
<html>
<head>
<title>README.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="multilayer-perceptron-mlp">Multilayer Perceptron (MLP)</h1>
<p><img src="file:///home/ubuntu/dev/makemore/pictures/MLP.png" alt="MLP"></p>
<p>MLP, following <a href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">Bengio et al. 2003</a></p>
<p><em><strong>Table of Contents</strong></em></p>
<!-- no toc -->
<ul>
<li><a href="#usage"><em>Usage</em></a></li>
<li><a href="#basic-setup"><em>Basic Setup</em></a></li>
</ul>
<h2 id="usage">Usage</h2>
<p>The included <code>names.txt</code> dataset, as an example, has the most common 32K names taken from <a href="https://www.ssa.gov/oact/babynames/">ssa.gov</a> for the year 2018. It looks like:</p>
<pre class="hljs"><code><div>emma
olivia
ava
isabella
sophia
charlotte
...
</div></code></pre>
<h2 id="basic-setup">Basic Setup</h2>
<p>First, we build the dataset to train.</p>
<pre class="hljs"><code><div><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline

<span class="hljs-comment"># read all the words in the file</span>
words = open(<span class="hljs-string">"../names.txt"</span>).read().splitlines()

<span class="hljs-comment"># build the vocabulary of characters and mapping to/from integers</span>
chars = sorted(list(set(<span class="hljs-string">''</span>.join(words))))
stoi = { ch: i + <span class="hljs-number">1</span> <span class="hljs-keyword">for</span> i, ch <span class="hljs-keyword">in</span> enumerate(chars) }
stoi[<span class="hljs-string">"."</span>] = <span class="hljs-number">0</span>
itos = { i: ch <span class="hljs-keyword">for</span> ch, i <span class="hljs-keyword">in</span> stoi.items() }

<span class="hljs-comment"># build the dataset</span>
block_size = <span class="hljs-number">3</span>  <span class="hljs-comment"># context length: how many characters do we take to predict the next one</span>
X, Y = [], []
<span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> words:
    
    print(w)
    context = [<span class="hljs-number">0</span>] * block_size
    <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> w + <span class="hljs-string">"."</span>:
        ix = stoi[ch]
        X.append(context)
        Y.append(ix)
        <span class="hljs-comment"># print(''.join([itos[i] for i in context]), '---&gt;', itos[ix])</span>
        context = context[<span class="hljs-number">1</span>:] + [ix]    <span class="hljs-comment"># crop and append</span>
        
X = torch.tensor(X)
Y = torch.tensor(Y)
</div></code></pre>
<p>How many samples do we have?</p>
<pre class="hljs"><code><div>len(words)  <span class="hljs-comment"># 32033</span>
</div></code></pre>
<p>Let's see how we transformed the dataset to features and labels.</p>
<pre class="hljs"><code><div>block_size = <span class="hljs-number">3</span>  <span class="hljs-comment"># using contiguous 3 characters to predict the next one</span>
X, Y = [], []
<span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> words[:<span class="hljs-number">3</span>]:
    print(w)
    context = [<span class="hljs-number">0</span>] * block_size
    <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> w + <span class="hljs-string">"."</span>:
        ix = stoi[ch]
        X.append(context)
        Y.append(ix)
        print(<span class="hljs-string">''</span>.join([itos[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> context]), <span class="hljs-string">'---&gt;'</span>, itos[ix])
        context = context[<span class="hljs-number">1</span>:] + [ix]    <span class="hljs-comment"># crop and append</span>
</div></code></pre>
<pre class="hljs"><code><div>emma
... ---&gt; e
..e ---&gt; m
.em ---&gt; m
emm ---&gt; a
mma ---&gt; .
olivia
... ---&gt; o
..o ---&gt; l
.ol ---&gt; i
oli ---&gt; v
liv ---&gt; i
ivi ---&gt; a
via ---&gt; .
ava
... ---&gt; a
..a ---&gt; v
.av ---&gt; a
ava ---&gt; .
</div></code></pre>
<h2 id="embedding">Embedding</h2>
<p>In this case, we want to embed the features into a 2D space. So, let's do it.</p>
<p>First, generate the embedding matrix.</p>
<pre class="hljs"><code><div>g = torch.Generator().manual_seed(<span class="hljs-number">2147483647</span>)   <span class="hljs-comment"># consistent with Andrej's settings</span>
C = torch.randn((<span class="hljs-number">27</span>, <span class="hljs-number">2</span>), generator=g)
</div></code></pre>
<p>Why $27 \times 2$? Because we map 27 characters ('a...z' + '.') to a 2D space.</p>
<p>simply run blow, we get a 3D tensor.</p>
<pre class="hljs"><code><div>emb = C[X]
emb.shape   <span class="hljs-comment"># torch.Size([228146, 3, 2])</span>
</div></code></pre>
<p>How <code>emb = C[X]</code> work? It's a kind of indexing. When indexing <code>C</code> with <code>X</code>, we get a 3D tensor. <strong>The first dimension is the same as <code>X</code>, and the last two dimensions are the same as <code>C</code>.</strong></p>
<p>For example. The embedding matrix <code>C</code> is below:</p>
<pre class="hljs"><code><div># C = torch.randn((27, 2), generator=g)
tensor([[ 1.5674, -0.2373],
        [-0.0274, -1.1008],
        [ 0.2859, -0.0296],
        [-1.5471,  0.6049],
        [ 0.0791,  0.9046],
        [-0.4713,  0.7868],
        [-0.3284, -0.4330],
        [ 1.3729,  2.9334],
        [ 1.5618, -1.6261],
        [ 0.6772, -0.8404],
        [ 0.9849, -0.1484],
        [-1.4795,  0.4483],
        [-0.0707,  2.4968],
        [ 2.4448, -0.6701],
        [-1.2199,  0.3031],
        [-1.0725,  0.7276],
        [ 0.0511,  1.3095],
        [-0.8022, -0.8504],
        [-1.8068,  1.2523],
        [ 0.1476, -1.0006],
        [-0.5030, -1.0660],
        [ 0.8480,  2.0275],
        [-0.1158, -1.2078],
        [-1.0406, -1.5367],
        [-0.5132,  0.2961],
        [-1.4904, -0.2838],
        [ 0.2569,  0.2130]])
</div></code></pre>
<p>Let's embed &quot;..e&quot; manually:</p>
<ol>
<li><code>..e</code> is <code>[0, 0, 5]</code> in <code>X</code> depending on the mapping <code>stoi</code>.</li>
<li><code>[0, 0, 5]</code> to index means <code>['the first row', 'the first row', 'the 6th row']</code> in <code>C</code>, so we get <code>[[ 1.5674, -0.2373], [ 1.5674, -0.2373], [ 0.4713,  0.7868]]</code>.</li>
</ol>
<p>Now check the result:</p>
<pre class="hljs"><code><div>emb[<span class="hljs-number">1</span>]  <span class="hljs-comment"># "..e" is the 2nd sample in X</span>
</div></code></pre>
<pre class="hljs"><code><div>tensor([[ 1.5674, -0.2373],
        [ 1.5674, -0.2373],
        [-0.4713,  0.7868]])    # exactly the same as we calculated.
</div></code></pre>
<p>Next, we want to flatten the 3D tensor to 2D, so we can use it as input to the MLP. Mapping <code>(228146, 3, 2)</code> to <code>(228146, 6)</code>. And Andrej gives us three ways to implement it.</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Method 1. Using torch.cat</span>
torch.cat([emb[:, <span class="hljs-number">0</span>, :], emb[:, <span class="hljs-number">1</span>, :], emb[:, <span class="hljs-number">2</span>, :]], dim=<span class="hljs-number">1</span>)

<span class="hljs-comment"># Method 2. Using torch.cat and torch.unbind</span>
torch.cat(torch.unbind(emb, <span class="hljs-number">1</span>), dim=<span class="hljs-number">1</span>)

<span class="hljs-comment"># Method 3. Using view</span>
emb.view(<span class="hljs-number">-1</span>, <span class="hljs-number">6</span>)
</div></code></pre>
<p>Let's check the equivalence:</p>
<pre class="hljs"><code><div>emb.view(<span class="hljs-number">32</span>, <span class="hljs-number">-1</span>) == torch.cat(torch.unbind(emb, <span class="hljs-number">1</span>), dim=<span class="hljs-number">1</span>)  
<span class="hljs-comment"># tensor([[True, True, True, True, True, True], ...]) --&gt; all True means equivalent</span>
</div></code></pre>
<p>The <code>view</code> is the most concise and efficient. The feasibility of <code>view</code> lies in the Pytorch's internal storage mechanism for tensors. For details, see <a href="http://blog.ezyang.com/2019/05/pytorch-internals/">PyTorch internals</a>.</p>

</body>
</html>
